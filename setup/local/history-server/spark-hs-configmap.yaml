# kubectl -n k8s-spark create cm spark-configs  \
# --from-file=spark-defaults.conf=setup/local/history-server/spark-defaults.conf \
# --from-file=spark.logserver.conf=setup/local/history-server/spark.logserver.conf \
# --from-literal=workload=HistoryServer \
# --dry-run=client -o yaml

#
# kubectl -n k8s-spark apply -f setup/local/history-server/spark-hs-configmap.yaml
# kubectl -n k8s-spark delete -f setup/local/history-server/spark-hs-configmap.yaml
---
apiVersion: v1
data:
  spark-defaults.conf: |-
    # Example:
    spark.serializer                          org.apache.spark.serializer.KryoSerializer

    #
    # spark.driver.memory                     5g
    # spark.executor.extraJavaOptions         -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"
    #

    #
    # Enable Spark jobs to Log In HDFS
    #
    spark.eventLog.enabled                    true
    spark.eventLog.dir                        file:///opt/spark/logs/
    spark.eventLog.rolling.enabled            true
    spark.eventLog.rolling.maxFileSize        128m
    
    #
    # History Server Related Properties
    #
    spark.history.provider                    org.apache.spark.deploy.history.FsHistoryProvider
    spark.history.fs.logDirectory             file:///opt/spark/logs/
    spark.history.fs.update.interval          10s
    spark.history.ui.port                     18080
    spark.yarn.historyServer.allowTracking    true

    #
    #
    #
    spark.ui.enabled                          false
    spark.ui.port                             18080
    spark.ui.filters                          org.apache.spark.deploy.yarn.YarnProxyRedirectFilter
    
    #
    #
  workload: HistoryServer
kind: ConfigMap
metadata:
  creationTimestamp: "2022-12-26T20:43:44Z"
  name: spark-configs
  namespace: k8s-spark
